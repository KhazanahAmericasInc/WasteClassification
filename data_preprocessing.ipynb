{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import os\n",
    "import sys\n",
    "import shutil, errno\n",
    "import zipfile as zf\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "\n",
    "\n",
    "###########################################################################     \n",
    "######################## data preprocessing ###############################\n",
    "###########################################################################\n",
    "'''\n",
    "create folder: original_data; processed_data\n",
    "\n",
    "get original data\n",
    "unzip file\n",
    "move data to the path of folder original_Data\n",
    "\n",
    "copy original_data and paste to processed_data so we can process data in the right folder\n",
    "split dataset into test and train subset\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "############################### Helper functions ###############################\n",
    "\n",
    "'''\n",
    "create the folders\n",
    "input: folders want to create in the format \"./xxx/\"\n",
    "output: void\n",
    "'''\n",
    "def create_folders(folders):\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            print(\"\\nCreated\", folder)\n",
    "        else:\n",
    "            inp = input('Do you clear the folder ' + folder + '?, y/n: ')\n",
    "            if inp.lower() == \"y\":\n",
    "                print(\"The folder will be cleared\")\n",
    "                try:\n",
    "                    shutil.rmtree(folder)\n",
    "                    os.makedirs(folder)\n",
    "                except OSError as e:\n",
    "                    print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "            elif inp.lower() == \"n\":\n",
    "                print(\"The folder will not be cleared\")\n",
    "            else:\n",
    "                print(\"Please type y/n\")\n",
    "    return\n",
    "\n",
    "\n",
    "'''\n",
    "unzip the folder to the same path\n",
    "input: zipfile to unzip\n",
    "output: void\n",
    "'''\n",
    "def unzip(zipfile):\n",
    "    files = zf.ZipFile(zipfile, 'r')\n",
    "    files.extractall()\n",
    "    files.close()\n",
    "    \n",
    "'''\n",
    "move files from one folder to another\n",
    "input: src folder and dst folder in format ./xxx/\n",
    "output: void\n",
    "'''\n",
    "def move_folder(src, dst):\n",
    "    try:\n",
    "        files = get_subsets(src)\n",
    "        for file in files:\n",
    "            shutil.move(src+file, dst)\n",
    "    except OSError as e:\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "        \n",
    "'''\n",
    "copy files from one folder to another\n",
    "input: src folder and dst folder in format ./xxx/\n",
    "output: void\n",
    "'''\n",
    "def copy_folder(src, dst):\n",
    "    try: \n",
    "        if os.path.exists(dst):\n",
    "            shutil.rmtree(dst)\n",
    "        shutil.copytree(src, dst)\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.ENOTDIR:\n",
    "            shutil.copy(Src, dst)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "'''\n",
    "get subsets (either files or folders) of the folder\n",
    "input: folder path\n",
    "output: list of name of subsets\n",
    "'''\n",
    "def get_subsets(path):\n",
    "    subsets = os.listdir(path)\n",
    "    for s in subsets:\n",
    "        if s.startswith('.'):\n",
    "            subsets.remove(s)\n",
    "    return subsets\n",
    "\n",
    "'''\n",
    "get path of subsets (either files or folders) of the folder\n",
    "input: folder path\n",
    "output: list of subsets path\n",
    "'''\n",
    "def get_subsets_path(path):\n",
    "    return glob(path+\"*/\")\n",
    "\n",
    "#strip the name from a path\n",
    "def get_name_from_path(f):\n",
    "    return f[f.rindex(\"/\")+1: ]\n",
    "\n",
    "'''\n",
    "split all data into train set and test set\n",
    "input: parent path of trainset folder and testset folder, the ratio of test/all data\n",
    "output: void\n",
    "'''\n",
    "def split_into_train_valid_and_test_sets(datapath, ratio1, ratio2):\n",
    "    assert ratio1 <= 1 and ratio1 >= 0\n",
    "    assert ratio2 <= 1 and ratio2 >= 0\n",
    "    test_path = os.path.join(datapath, \"test/\")\n",
    "    valid_path = os.path.join(datapath, \"valid/\")\n",
    "    train_path = os.path.join(datapath, \"train/\")\n",
    "    print(test_path)\n",
    "    subset_paths = get_subsets_path(train_path)\n",
    "    subsets = get_subsets(train_path)\n",
    "    print(subset_paths)\n",
    "    print(subsets)\n",
    "    for i, path in enumerate(subset_paths):\n",
    "        curr = subsets[i]\n",
    "\n",
    "        temp = valid_path + curr + \"/\"\n",
    "        os.makedirs(os.path.dirname(temp), exist_ok=True)\n",
    "        \n",
    "        images = glob(path + \"*.jpg\")\n",
    "        rand = random.sample(images, int(ratio1*len(images)))\n",
    "        print(curr , \" -- size of non-trainset: \" , len(rand) , \", size of trainset: \" , (len(images)-len(rand)))\n",
    "\n",
    "        for image in rand:\n",
    "            dst = temp + get_name_from_path(image)\n",
    "            os.rename(image, dst)\n",
    "    \n",
    "    subset_paths = get_subsets_path(valid_path)\n",
    "    subsets = get_subsets(valid_path)\n",
    "    print(subset_paths)\n",
    "    print(subsets)\n",
    "    for i, path in enumerate(subset_paths):\n",
    "        curr = subsets[i]\n",
    "\n",
    "        temp = test_path + curr + \"/\"\n",
    "        os.makedirs(os.path.dirname(temp), exist_ok=True)\n",
    "        \n",
    "        images = glob(path + \"*.jpg\")\n",
    "        rand = random.sample(images, int(ratio2*len(images)))\n",
    "        print(curr , \" -- size of testset: \" , len(rand) , \", size of validset: \" , (len(images)-len(rand)))\n",
    "\n",
    "        for image in rand:\n",
    "            dst = temp + get_name_from_path(image)\n",
    "            os.rename(image, dst)\n",
    "    \n",
    "            \n",
    "            \n",
    "######################### main functions #########################          \n",
    "'''\n",
    "do the whole process of data processing with all the helper functions\n",
    "input: using_colab: import data from different location; \n",
    "        if using_colab is 1, we are using colab\n",
    "        else is 0, we are using local machine\n",
    "        else, the user input is wrong, do nothing\n",
    "output: data\n",
    "'''\n",
    "def process_data(using_colab):\n",
    "\n",
    "    if using_colab == 1:\n",
    "        print(\"Importing data from google drive\")\n",
    "        ############## if compile on google colab #################\n",
    "        # Load the Drive helper and mount\n",
    "        from google.colab import drive\n",
    "\n",
    "        # This will prompt for authorization.\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "        # !ls \"/content/drive/My Drive\"\n",
    "        # os.chdir(\"../\")\n",
    "        datapath = \"./processed_data/\"\n",
    "        test_path = os.path.join(datapath, \"test\")\n",
    "        valid_path = os.path.join(datapath, \"valid\")\n",
    "        train_path = os.path.join(datapath, \"train\")\n",
    "        folders = [\"./original_data/\", datapath, test_path, train_path, valid_path, \"./trained_models/\"]\n",
    "        create_folders(folders)\n",
    "        unzip(\"/content/drive/My Drive/dataset-resized.zip\")\n",
    "        move_folder(\"./dataset-resized/\", \"./original_data\")\n",
    "        copy_folder(\"./original_data/\", train_path)\n",
    "        waste_types = get_subsets(datapath)\n",
    "        split_into_train_valid_and_test_sets(datapath, 0.4, 0.5)\n",
    "\n",
    "\n",
    "        path = Path(os.getcwd())/\"processed_data\"\n",
    "        tfms = get_transforms(do_flip=True, flip_vert=True)\n",
    "        data = ImageDataBunch.from_folder(path, test=\"test\", ds_tfms=tfms, bs=16)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    elif using_colab == 0:\n",
    "        print(\"Importing data from local machine\")\n",
    "        ########## if compile locally ###############\n",
    "        datapath = \"./processed_data/\"\n",
    "        test_path = os.path.join(datapath, \"test\")\n",
    "        valid_path = os.path.join(datapath, \"valid\")\n",
    "        train_path = os.path.join(datapath, \"train\")\n",
    "        folders = [\"./original_data/\", datapath, test_path, train_path, valid_path, \"./trained_models/\"]\n",
    "        create_folders(folders)\n",
    "        unzip(\"dataset-resized.zip\")\n",
    "        move_folder(\"./dataset-resized/\", \"./original_data\")\n",
    "        copy_folder(\"./original_data/\", train_path)\n",
    "        waste_types = get_subsets(datapath)\n",
    "        split_into_train_valid_and_test_sets(datapath, 0.4, 0.5)\n",
    "\n",
    "\n",
    "        path = Path(os.getcwd())/\"processed_data\"\n",
    "        tfms = get_transforms(do_flip=True, flip_vert=True)\n",
    "        data = ImageDataBunch.from_folder(path, test=\"test\", ds_tfms=tfms, bs=16)\n",
    "\n",
    "        return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
