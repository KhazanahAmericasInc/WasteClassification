# -*- coding: utf-8 -*-
"""model_training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/113ASpKO93ppoWy3ElWZRpL7IkHYPbvph
"""

###########################################################################     
############################ model training ###############################
###########################################################################


inp = input('Are you compiling on google colab?, y/n: ')
if inp.lower() == "y":
    print("We are using google colab")
    ############## if compile on google colab #################
    !pip install import-ipynb
    import import_ipynb

    !pip install -U -q PyDrive
    from pydrive.auth import GoogleAuth
    from pydrive.drive import GoogleDrive
    from google.colab import auth
    from oauth2client.client import GoogleCredentials

    auth.authenticate_user()
    gauth = GoogleAuth()
    gauth.credentials = GoogleCredentials.get_application_default()
    drive = GoogleDrive(gauth)

    your_module = drive.CreateFile({'id':'1wCNx7SWrCPL78UmmzEF6pAfdniCVJUWS'})
    # https://drive.google.com/open?id=1wCNx7SWrCPL78UmmzEF6pAfdniCVJUWS
    your_module.GetContentFile('data_preprocessing.ipynb')
    import data_preprocessing as dp
    
    data = dp.process_data(1)
    
    
elif inp.lower() == "n":
    print("We are using local machine")
    ########## if compile locally ###############
    import data_preprocessing as dp
    
    data = dp.process_data(0)
else:
    print("Please reply y/n")
    
    


from fastai.vision import *
from fastai.metrics import error_rate
from sklearn.metrics import confusion_matrix

learn = cnn_learner(data,models.resnet34,metrics=error_rate)

learn.model

learn.lr_find(start_lr=1e-6,end_lr=1e1)
learn.recorder.plot()

learn.fit_one_cycle(20,max_lr=3.6e-03)

preds = learn.get_preds(ds_type=DatasetType.Test)

max_idxs = np.asarray(np.argmax(preds[0],axis=1))

yhat = []
for max_idx in max_idxs:
    yhat.append(data.classes[max_idx])

learn.data.test_ds[0][0]

y = []

## convert POSIX paths to string first
for label_path in data.test_ds.items:
    y.append(str(label_path))
    
## then extract waste type from file path
pattern = re.compile("([a-z]+)[0-9]+")
for i in range(len(y)):
    y[i] = pattern.search(y[i]).group(1)

## predicted values
print(yhat[300:305])
## actual values
print(y[300:305])

cm = confusion_matrix(y,yhat)
print(cm)

correct = 0

for r in range(len(cm)):
    for c in range(len(cm)):
        if (r==c):
            correct += cm[r,c]

accuracy = correct/sum(sum(cm))
accuracy

############## error analysis ###############
interpretation = ClassificationInterpretation.from_learner(learn)
interpretation.most_confused(min_val=2)

"""The model confused glass for metal and trash for paper 5 times."""

learn.summary()

############## model saving/output ###############
# from datetime import datetime
# t = datetime.today().strftime('%Y-%m-%d')
from time import gmtime, strftime
t = strftime("%Y-%m-%d %H:%M:%S", gmtime())
output_name = "waste_classification_" + t
output_path = "../../trained_models/" + output_name 

learn.save(output_path, return_path=True)

############ model loading ################
model_load = cnn_learner(data,models.resnet34,metrics=error_rate)
model_load = model_load.load('/content/processed_data/models/../../trained_models/waste_classification_2019-05-23 21:56:02')

import datetime
start_time = datetime.datetime.now()
preds = learn.get_preds(ds_type=DatasetType.Test)
end_time = datetime.datetime.now()
duration = (end_time - start_time).total_seconds() * 1000
print(duration)

preds_load = model_load.get_preds(ds_type=DatasetType.Test)

import glob
file_size = len(glob.glob('./processed_data/test/*/*'))

speed = duration/file_size
print("CPU speed is ")
print(speed)
print("/milliseconds")

max_idxs = np.asarray(np.argmax(preds_load[0],axis=1))

yhat = []
for max_idx in max_idxs:
    yhat.append(data.classes[max_idx])

y = []

## convert POSIX paths to string first
for label_path in data.test_ds.items:
    y.append(str(label_path))
    
## then extract waste type from file path
pattern = re.compile("([a-z]+)[0-9]+")
for i in range(len(y)):
    y[i] = pattern.search(y[i]).group(1)

cm = confusion_matrix(y,yhat)
print(cm)

correct = 0

for r in range(len(cm)):
    for c in range(len(cm)):
        if (r==c):
            correct += cm[r,c]

accuracy = correct/sum(sum(cm))
accuracy