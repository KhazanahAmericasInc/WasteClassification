{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVP7I1fBWgfs"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import os\n",
    "import sys\n",
    "import shutil, errno\n",
    "import zipfile as zf\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "\n",
    "\n",
    "###########################################################################     \n",
    "######################## data preprocessing ###############################\n",
    "###########################################################################\n",
    "'''\n",
    "create folder: original_data; processed_data\n",
    "\n",
    "get original data\n",
    "unzip file\n",
    "move data to the path of folder original_Data\n",
    "\n",
    "copy original_data and paste to processed_data so we can process data in the right folder\n",
    "split dataset into test and train subset\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "############################### Helper functions ###############################\n",
    "\n",
    "'''\n",
    "create the folders\n",
    "input: folders want to create in the format \"./xxx/\"\n",
    "output: void\n",
    "'''\n",
    "def create_folders(folders):\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            print(\"\\nCreated\", folder)\n",
    "        else:\n",
    "            inp = input('Do you clear the folder ' + folder + '?, y/n: ')\n",
    "            if inp.lower() == \"y\":\n",
    "                print(\"The folder will be cleared\")\n",
    "                try:\n",
    "                    shutil.rmtree(folder)\n",
    "                    os.makedirs(folder)\n",
    "                except OSError as e:\n",
    "                    print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "            elif inp.lower() == \"n\":\n",
    "                print(\"The folder will not be cleared\")\n",
    "            else:\n",
    "                print(\"Please type y/n\")\n",
    "    return  \n",
    "\n",
    "'''\n",
    "unzip the folder to the same path\n",
    "input: zipfile to unzip\n",
    "output: void\n",
    "'''\n",
    "def unzip(zipfile):\n",
    "    files = zf.ZipFile(zipfile, 'r')\n",
    "    files.extractall()\n",
    "    files.close()\n",
    "    \n",
    "'''\n",
    "move files from one folder to another\n",
    "input: src folder and dst folder in format ./xxx/\n",
    "output: void\n",
    "'''\n",
    "def move_folder(src, dst):\n",
    "    try:\n",
    "        files = get_subsets(src)\n",
    "        for file in files:\n",
    "            shutil.move(src+file, dst)\n",
    "        if len(os.listdir(src)) == 0:\n",
    "            os.rmdir(src)\n",
    "    except OSError as e:\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "\n",
    "def rename_and_move_images(src, dst):\n",
    "    try:\n",
    "        files = get_subsets(src)\n",
    "        for file in files:\n",
    "            s = rename_image_name(file)\n",
    "            os.rename(src + file, dst + s)\n",
    "#             shutil.move(src+file, dst)\n",
    "        os.rmdir(src)\n",
    "    except OSError as e:\n",
    "        print (\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "\n",
    "    \n",
    "def rename_image_name(waste):\n",
    "    if waste.startswith(\"plastic\"):\n",
    "        s = convert_name(waste, \"recycle\", \"plastic\") + \"001\" + \".jpg\"\n",
    "    elif waste.startswith(\"metal\"):\n",
    "        s = convert_name(waste, \"recycle\", \"metal\") + \"002\" + \".jpg\"\n",
    "    elif waste.startswith(\"cardboard\"):\n",
    "        s = convert_name(waste, \"compost\", \"cardboard\") + \"001\" + \".jpg\"\n",
    "    elif waste.startswith(\"paper\"):\n",
    "        s = convert_name(waste, \"compost\", \"paper\") + \"002\" + \".jpg\"\n",
    "#     elif waste.startswith(\"trash\"):\n",
    "#         s = waste[:-4] + \"001\" + \".jpg\"\n",
    "    elif waste.startswith(\"glass\"):\n",
    "        s = convert_name(waste, \"recycle\", \"glass\") + \"003\" + \".jpg\"\n",
    "    else:\n",
    "        s = waste\n",
    "    return s\n",
    "  \n",
    "def convert_name(src, dst, type):\n",
    "  s = dst + src[len(type):-4]\n",
    "  return s\n",
    "        \n",
    "'''\n",
    "copy files from one folder to another\n",
    "input: src folder and dst folder in format ./xxx/\n",
    "output: void\n",
    "'''\n",
    "def copy_folder(src, dst):\n",
    "    try: \n",
    "        if os.path.exists(dst):\n",
    "            shutil.rmtree(dst)\n",
    "        shutil.copytree(src, dst)\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.ENOTDIR:\n",
    "            shutil.copy(Src, dst)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "'''\n",
    "get subsets (either files or folders) of the folder\n",
    "input: folder path\n",
    "output: list of name of subsets\n",
    "'''\n",
    "def get_subsets(path):\n",
    "    subsets = os.listdir(path)\n",
    "    for s in subsets:\n",
    "        if s.startswith('.'):\n",
    "            subsets.remove(s)\n",
    "    return subsets\n",
    "\n",
    "'''\n",
    "get path of subsets (either files or folders) of the folder\n",
    "input: folder path\n",
    "output: list of subsets path\n",
    "'''\n",
    "def get_subsets_path(path):\n",
    "    return glob(path+\"*/\")\n",
    "\n",
    "#strip the name from a path\n",
    "def get_name_from_path(f):\n",
    "    return f[f.rindex(\"/\")+1: ]\n",
    "\n",
    "'''\n",
    "split all data into train set and test set\n",
    "input: parent path of trainset folder and testset folder, the ratio of test/all data\n",
    "output: void\n",
    "'''\n",
    "def split_into_train_valid_and_test_sets(datapath, ratio1, ratio2):\n",
    "    assert ratio1 <= 1 and ratio1 >= 0\n",
    "    assert ratio2 <= 1 and ratio2 >= 0\n",
    "    test_path = os.path.join(datapath, \"test/\")\n",
    "    valid_path = os.path.join(datapath, \"valid/\")\n",
    "    train_path = os.path.join(datapath, \"train/\")\n",
    "    print(test_path)\n",
    "    subset_paths = get_subsets_path(train_path)\n",
    "    subsets = get_subsets(train_path)\n",
    "    print(subset_paths)\n",
    "    print(subsets)\n",
    "    for i, path in enumerate(subset_paths):\n",
    "        curr = subsets[i]\n",
    "\n",
    "        temp = valid_path + curr + \"/\"\n",
    "        os.makedirs(os.path.dirname(temp), exist_ok=True)\n",
    "        \n",
    "        images = glob(path + \"*.jpg\")\n",
    "        rand = random.sample(images, int(ratio1*len(images)))\n",
    "        print(curr , \" -- size of non-trainset: \" , len(rand) , \", size of trainset: \" , (len(images)-len(rand)))\n",
    "\n",
    "        for image in rand:\n",
    "            dst = temp + get_name_from_path(image)\n",
    "            os.rename(image, dst)\n",
    "    \n",
    "    subset_paths = get_subsets_path(valid_path)\n",
    "    subsets = get_subsets(valid_path)\n",
    "    print(subset_paths)\n",
    "    print(subsets)\n",
    "    for i, path in enumerate(subset_paths):\n",
    "        curr = subsets[i]\n",
    "\n",
    "        temp = test_path + curr + \"/\"\n",
    "        os.makedirs(os.path.dirname(temp), exist_ok=True)\n",
    "        \n",
    "        images = glob(path + \"*.jpg\")\n",
    "        rand = random.sample(images, int(ratio2*len(images)))\n",
    "        print(curr , \" -- size of testset: \" , len(rand) , \", size of validset: \" , (len(images)-len(rand)))\n",
    "\n",
    "        for image in rand:\n",
    "            dst = temp + get_name_from_path(image)\n",
    "            os.rename(image, dst)\n",
    "\n",
    "            \n",
    "######################### main functions #########################          \n",
    "'''\n",
    "do the whole process of data processing with all the helper functions\n",
    "input: using_colab: import data from different location; \n",
    "        if using_colab is 1, we are using colab\n",
    "        else is 0, we are using local machine\n",
    "        else, the user input is wrong, do nothing\n",
    "output: data\n",
    "'''\n",
    "def process_data(using_colab):\n",
    "\n",
    "    if using_colab == 1:\n",
    "        print(\"Importing data from google drive\")\n",
    "        ############## if compile on google colab #################\n",
    "        # Load the Drive helper and mount\n",
    "        from google.colab import drive\n",
    "\n",
    "        # This will prompt for authorization.\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "        # !ls \"/content/drive/My Drive\"\n",
    "        # os.chdir(\"../\")\n",
    "        datapath = \"./processed_data/\"\n",
    "        test_path = os.path.join(datapath, \"test\")\n",
    "        valid_path = os.path.join(datapath, \"valid\")\n",
    "        train_path = os.path.join(datapath, \"train\")\n",
    "        folders = [\"./original_data/\", datapath, test_path, train_path, valid_path, \"./trained_models/\"]\n",
    "        create_folders(folders)\n",
    "        unzip(\"/content/drive/My Drive/dataset-resized.zip\")\n",
    "        move_folder(\"./dataset-resized/\", \"./original_data\")\n",
    "        \n",
    "        \n",
    "        waste_types = [\"compost\", \"recycle\"]\n",
    "        waste_paths = [\"./original_data/\"+ w + \"/\" for w in waste_types]\n",
    "        create_folders(waste_paths)\n",
    "        rename_and_move_images(\"./original_data/plastic/\",\"./original_data/recycle/\")\n",
    "        rename_and_move_images(\"./original_data/metal/\",\"./original_data/recycle/\")\n",
    "        rename_and_move_images(\"./original_data/glass/\",\"./original_data/recycle/\")\n",
    "        rename_and_move_images(\"./original_data/cardboard/\",\"./original_data/compost/\")\n",
    "        rename_and_move_images(\"./original_data/paper/\",\"./original_data/compost/\")\n",
    "        \n",
    "        copy_folder(\"./original_data/\", train_path)\n",
    "        \n",
    "        split_into_train_valid_and_test_sets(datapath, 0.4, 0.5)\n",
    "\n",
    "\n",
    "        path = Path(os.getcwd())/\"processed_data\"\n",
    "        tfms = get_transforms(do_flip=True, flip_vert=True)\n",
    "        data = ImageDataBunch.from_folder(path, test=\"test\", ds_tfms=tfms, bs=16)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    elif using_colab == 0:\n",
    "        print(\"Importing data from local machine\")\n",
    "        ########## if compile locally ###############\n",
    "        datapath = \"./processed_data/\"\n",
    "        test_path = os.path.join(datapath, \"test\")\n",
    "        valid_path = os.path.join(datapath, \"valid\")\n",
    "        train_path = os.path.join(datapath, \"train\")\n",
    "        folders = [\"./original_data/\", datapath, test_path, train_path, valid_path, \"./trained_models/\"]\n",
    "        create_folders(folders)\n",
    "        unzip(\"dataset-resized.zip\")\n",
    "        move_folder(\"./dataset-resized/\", \"./original_data\")\n",
    "        \n",
    "        waste_types = [\"compost\", \"recycle\"]\n",
    "        waste_paths = [\"./original_data/\"+ w + \"/\" for w in waste_types]\n",
    "        create_folders(waste_paths)\n",
    "        rename_and_move_images(\"./original_data/plastic/\",\"./original_data/recycle/\")\n",
    "        rename_and_move_images(\"./original_data/metal/\",\"./original_data/recycle/\")\n",
    "        rename_and_move_images(\"./original_data/glass/\",\"./original_data/recycle/\")\n",
    "        rename_and_move_images(\"./original_data/cardboard/\",\"./original_data/compost/\")\n",
    "        rename_and_move_images(\"./original_data/paper/\",\"./original_data/compost/\")\n",
    "        \n",
    "        copy_folder(\"./original_data/\", train_path)\n",
    "        \n",
    "        split_into_train_valid_and_test_sets(datapath, 0.4, 0.5)\n",
    "\n",
    "\n",
    "        path = Path(os.getcwd())/\"processed_data\"\n",
    "        tfms = get_transforms(do_flip=True, flip_vert=True)\n",
    "        data = ImageDataBunch.from_folder(path, test=\"test\", ds_tfms=tfms, bs=16)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "id": "bn4EqhjmZmve",
    "outputId": "f9c0ba51-bd34-456d-8b8a-0e7034e97938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data from google drive\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Do you clear the folder ./original_data/?, y/n: y\n",
      "The folder will be cleared\n",
      "Do you clear the folder ./processed_data/?, y/n: y\n",
      "The folder will be cleared\n",
      "\n",
      "Created ./processed_data/test\n",
      "\n",
      "Created ./processed_data/train\n",
      "\n",
      "Created ./processed_data/valid\n",
      "Do you clear the folder ./trained_models/?, y/n: y\n",
      "The folder will be cleared\n",
      "\n",
      "Created ./original_data/compost/\n",
      "\n",
      "Created ./original_data/recycle/\n",
      "#######TEST#######\n",
      "#######TEST#######\n",
      "#######TEST#######\n",
      "#######TEST#######\n",
      "#######TEST#######\n",
      "./processed_data/test/\n",
      "['./processed_data/train/trash/', './processed_data/train/recycle/', './processed_data/train/compost/']\n",
      "['trash', 'recycle', 'compost']\n",
      "trash  -- size of non-trainset:  255 , size of trainset:  383\n",
      "recycle  -- size of non-trainset:  356 , size of trainset:  536\n",
      "compost  -- size of non-trainset:  398 , size of trainset:  599\n",
      "['./processed_data/valid/trash/', './processed_data/valid/recycle/', './processed_data/valid/compost/']\n",
      "['trash', 'recycle', 'compost']\n",
      "trash  -- size of testset:  127 , size of validset:  128\n",
      "recycle  -- size of testset:  178 , size of validset:  178\n",
      "compost  -- size of testset:  199 , size of validset:  199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (1518 items)\n",
       "x: ImageList\n",
       "Image (3, 384, 512),Image (3, 384, 512),Image (3, 384, 512),Image (3, 384, 512),Image (3, 384, 512)\n",
       "y: CategoryList\n",
       "trash,trash,trash,trash,trash\n",
       "Path: /content/processed_data;\n",
       "\n",
       "Valid: LabelList (505 items)\n",
       "x: ImageList\n",
       "Image (3, 384, 512),Image (3, 384, 512),Image (3, 384, 512),Image (3, 384, 512),Image (3, 384, 512)\n",
       "y: CategoryList\n",
       "trash,trash,trash,trash,trash\n",
       "Path: /content/processed_data;\n",
       "\n",
       "Test: LabelList (504 items)\n",
       "x: ImageList\n",
       "Image (3, 384, 512),Image (3, 384, 512),Image (3, 384, 512),Image (3, 384, 512),Image (3, 384, 512)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: /content/processed_data"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process_data(1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "data_preprocessing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
