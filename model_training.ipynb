{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you compiling on google colab?, y/n: n\n",
      "We are using local machine\n",
      "Do you clear the folder ./original_data/?, y/n: m\n",
      "Please type y/n\n",
      "Do you clear the folder ./processed_data/?, y/n: n\n",
      "The folder will not be cleared\n",
      "Do you clear the folder ./processed_data/test?, y/n: n\n",
      "The folder will not be cleared\n",
      "Do you clear the folder ./processed_data/train?, y/n: n\n",
      "The folder will not be cleared\n",
      "Do you clear the folder ./processed_data/valid?, y/n: n\n",
      "The folder will not be cleared\n",
      "Do you clear the folder ./trained_models/?, y/n: n\n",
      "The folder will not be cleared\n",
      "Error: None - None.\n",
      "./processed_data/test/\n",
      "['./processed_data/train/paper/', './processed_data/train/metal/', './processed_data/train/cardboard/', './processed_data/train/trash/', './processed_data/train/glass/', './processed_data/train/plastic/']\n",
      "['paper', 'metal', 'cardboard', 'trash', 'glass', 'plastic']\n",
      "paper  -- size of non-trainset:  237 , size of trainset:  357\n",
      "metal  -- size of non-trainset:  164 , size of trainset:  246\n",
      "cardboard  -- size of non-trainset:  161 , size of trainset:  242\n",
      "trash  -- size of non-trainset:  54 , size of trainset:  83\n",
      "glass  -- size of non-trainset:  200 , size of trainset:  301\n",
      "plastic  -- size of non-trainset:  192 , size of trainset:  290\n",
      "['./processed_data/valid/paper/', './processed_data/valid/metal/', './processed_data/valid/cardboard/', './processed_data/valid/trash/', './processed_data/valid/glass/', './processed_data/valid/plastic/']\n",
      "['paper', 'metal', 'cardboard', 'trash', 'glass', 'plastic']\n",
      "paper  -- size of testset:  164 , size of validset:  165\n",
      "metal  -- size of testset:  115 , size of validset:  115\n",
      "cardboard  -- size of testset:  113 , size of validset:  113\n",
      "trash  -- size of testset:  39 , size of validset:  39\n",
      "glass  -- size of testset:  141 , size of validset:  141\n",
      "plastic  -- size of testset:  132 , size of validset:  133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/envs/tf/lib/python3.7/site-packages/fastai/vision/learner.py:105: UserWarning: `create_cnn` is deprecated and is now named `cnn_learner`.\n",
      "  warn(\"`create_cnn` is deprecated and is now named `cnn_learner`.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='18' class='' max='94', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      19.15% [18/94 06:25<27:07 2.3249]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########################################################################     \n",
    "############################ model training ###############################\n",
    "###########################################################################\n",
    "\n",
    "\n",
    "inp = input('Are you compiling on google colab?, y/n: ')\n",
    "if inp.lower() == \"y\":\n",
    "    print(\"We are using google colab\")\n",
    "    ############## if compile on google colab #################\n",
    "    !pip install import-ipynb\n",
    "    import import_ipynb\n",
    "\n",
    "    !pip install -U -q PyDrive\n",
    "    from pydrive.auth import GoogleAuth\n",
    "    from pydrive.drive import GoogleDrive\n",
    "    from google.colab import auth\n",
    "    from oauth2client.client import GoogleCredentials\n",
    "\n",
    "    auth.authenticate_user()\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.credentials = GoogleCredentials.get_application_default()\n",
    "    drive = GoogleDrive(gauth)\n",
    "\n",
    "    your_module = drive.CreateFile({'id':'1wCNx7SWrCPL78UmmzEF6pAfdniCVJUWS'})\n",
    "    # https://drive.google.com/open?id=1wCNx7SWrCPL78UmmzEF6pAfdniCVJUWS\n",
    "    your_module.GetContentFile('data_preprocessing.ipynb')\n",
    "    import data_preprocessing as dp\n",
    "    \n",
    "    data = dp.process_data(1)\n",
    "    \n",
    "    \n",
    "elif inp.lower() == \"n\":\n",
    "    print(\"We are using local machine\")\n",
    "    ########## if compile locally ###############\n",
    "    import data_preprocessing as dp\n",
    "    \n",
    "    data = dp.process_data(0)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Please reply y/n\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data,models.resnet34,metrics=error_rate)\n",
    "\n",
    "learn.model\n",
    "\n",
    "learn.lr_find(start_lr=1e-6,end_lr=1e1)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(20,max_lr=3.13e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idxs = np.asarray(np.argmax(preds[0],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = []\n",
    "for max_idx in max_idxs:\n",
    "    yhat.append(data.classes[max_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data.test_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "\n",
    "## convert POSIX paths to string first\n",
    "for label_path in data.test_ds.items:\n",
    "    y.append(str(label_path))\n",
    "    \n",
    "## then extract waste type from file path\n",
    "pattern = re.compile(\"([a-z]+)[0-9]+\")\n",
    "for i in range(len(y)):\n",
    "    y[i] = pattern.search(y[i]).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predicted values\n",
    "print(yhat[0:5])\n",
    "## actual values\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y,yhat)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "\n",
    "for r in range(len(cm)):\n",
    "    for c in range(len(cm)):\n",
    "        if (r==c):\n",
    "            correct += cm[r,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correct/sum(sum(cm))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
